═══════════════════════════════════════════════════════════════════════════════
PMC-VQA SFT PIPELINE - WORKFLOW DIAGRAM
═══════════════════════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────────────────────┐
│                             INPUT DATA & MODELS                             │
└─────────────────────────────────────────────────────────────────────────────┘

    ┌─────────────────────┐         ┌──────────────────────────────┐
    │   PMC-VQA Dataset   │         │  DeepSeek-R1-Distill-Llama   │
    │                     │         │         (8B Model)           │
    │  • train.csv        │         │                              │
    │  • test.csv         │         │  • Tokenizer                 │
    │  • ~227K examples   │         │  • Model weights             │
    │  • Medical images   │         │  • Config files              │
    └──────────┬──────────┘         └──────────────┬───────────────┘
               │                                   │
               └───────────────┬───────────────────┘
                               │
                               ▼

┌─────────────────────────────────────────────────────────────────────────────┐
│                          STEP 1: PREPROCESSING                              │
└─────────────────────────────────────────────────────────────────────────────┘

    ┌──────────────────────────────────────────────────────────────┐
    │  🧪 TEST: test_preprocessing.py                              │
    │     └─> Quick validation with 10 samples (~30 seconds)       │
    └──────────────────────────────────────────────────────────────┘
                               │
                               ▼
    ┌──────────────────────────────────────────────────────────────┐
    │  🔧 MAIN: preprocess_pmc_vqa_for_sft.py                      │
    │                                                              │
    │  Input:  CSV files (Question, Answer, Choices)               │
    │          ↓                                                   │
    │  Process:                                                    │
    │    1. Load dataset                                           │
    │    2. Format as chat conversations                           │
    │    3. Apply DeepSeek-R1 template                             │
    │    4. Tokenize with padding/truncation                       │
    │    5. Create labels for SFT                                  │
    │          ↓                                                   │
    │  Output: Tokenized dataset (input_ids, labels, etc.)         │
    │          + examples.json for inspection                      │
    │                                                              │
    │  Time: ~30-60 minutes for full dataset                       │
    └──────────────────────────────────────────────────────────────┘
                               │
                               ▼
                  ┌────────────────────────┐
                  │  PMC-VQA-Processed/    │
                  │  • train/ (tokenized)  │
                  │  • test/ (tokenized)   │
                  │  • examples.json       │
                  └────────────┬───────────┘
                               │
                               ▼

┌─────────────────────────────────────────────────────────────────────────────┐
│                          STEP 2: FINE-TUNING                                │
└─────────────────────────────────────────────────────────────────────────────┘

    ┌──────────────────────────────────────────────────────────────┐
    │  🚂 TRAIN: train_sft_example.py                              │
    │                                                              │
    │  Configuration:                                              │
    │    • 8-bit quantization (memory efficient)                   │
    │    • LoRA fine-tuning (0.88% params trained)                 │
    │    • Gradient accumulation (large batch size)                │
    │    • Mixed precision (BF16)                                  │
    │    • Checkpoint saving                                       │
    │                                                              │
    │  Training Process:                                           │
    │    1. Load base model + tokenizer                            │
    │    2. Setup LoRA (r=16, alpha=32)                            │
    │    3. Load preprocessed dataset                              │
    │    4. Train with HF Trainer                                  │
    │    5. Evaluate on test set                                   │
    │    6. Save best checkpoint                                   │
    │                                                              │
    │  Time: ~8-12 hours on A100                                   │
    │  Memory: ~24-40 GB GPU VRAM                                  │
    └──────────────────────────────────────────────────────────────┘
                               │
                               ▼
                  ┌────────────────────────┐
                  │  PMC-VQA-SFT-Output/   │
                  │  • checkpoint-*/       │
                  │  • final_model/        │
                  │    - adapter_model.bin │
                  │    - config.json       │
                  │  • eval_results.json   │
                  └────────────┬───────────┘
                               │
                               ▼

┌─────────────────────────────────────────────────────────────────────────────┐
│                       STEP 3: INFERENCE & EVALUATION                        │
└─────────────────────────────────────────────────────────────────────────────┘

    ┌──────────────────────────────────────────────────────────────┐
    │  💬 INFERENCE: inference_example.py                          │
    │                                                              │
    │  Modes:                                                      │
    │    1. 🎮 Demo Mode (default)                                 │
    │       └─> Shows example medical questions                    │
    │                                                              │
    │    2. 💬 Interactive Mode (--interactive)                    │
    │       └─> Live Q&A session                                   │
    │                                                              │
    │    3. 📊 Evaluation Mode (--evaluate)                        │
    │       └─> Test on dataset samples                            │
    │                                                              │
    │    4. ⚡ Single Question (--question "...")                   │
    │       └─> Quick API-style inference                          │
    │                                                              │
    │  Features:                                                   │
    │    • Load fine-tuned model                                   │
    │    • Apply chat template                                     │
    │    • Generate answers                                        │
    │    • Save results to JSON                                    │
    └──────────────────────────────────────────────────────────────┘
                               │
                               ▼
              ┌─────────────────────────────────┐
              │     RESULTS & APPLICATIONS      │
              │                                 │
              │  • Medical Q&A system           │
              │  • Educational tools            │
              │  • Research baseline            │
              │  • Clinical support             │
              └─────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════
FILE STRUCTURE
═══════════════════════════════════════════════════════════════════════════════

📂 mperform/
│
├── 📘 Documentation (READ FIRST!)
│   ├── README_PMC_VQA_SFT.md           ⭐ Main README (start here!)
│   ├── QUICKSTART_GUIDE.md             ⭐ Step-by-step guide
│   ├── PMC_VQA_PREPROCESSING_README.md    Preprocessing details
│   ├── FILES_SUMMARY.md                   Complete file overview
│   └── WORKFLOW_DIAGRAM.txt               This file
│
├── 🐍 Python Scripts
│   ├── test_preprocessing.py           🧪 Test preprocessing (30 sec)
│   ├── preprocess_pmc_vqa_for_sft.py   🔧 Main preprocessing (60 min)
│   ├── train_sft_example.py            🚂 Training script (8-12 hrs)
│   └── inference_example.py            💬 Inference & evaluation
│
├── 📦 Input Data
│   ├── PMC-VQA/                        Dataset (227K examples)
│   │   ├── train.csv
│   │   ├── test.csv
│   │   └── hf_dataset/
│   │
│   └── DeepSeek-R1-Distill-Llama-8B/   Base model (8B params)
│       ├── config.json
│       ├── tokenizer.json
│       └── model*.safetensors
│
└── 🎯 Output Data (Created)
    ├── PMC-VQA-Processed/              Preprocessed dataset
    │   ├── train/
    │   ├── test/
    │   └── examples.json
    │
    └── PMC-VQA-SFT-Output/             Fine-tuned model
        ├── checkpoint-*/
        ├── final_model/
        └── eval_results.json


═══════════════════════════════════════════════════════════════════════════════
QUICK COMMAND REFERENCE
═══════════════════════════════════════════════════════════════════════════════

# 1️⃣ Test (30 seconds)
python test_preprocessing.py

# 2️⃣ Preprocess (30-60 minutes)
python preprocess_pmc_vqa_for_sft.py

# 3️⃣ Quick training test (10 minutes)
python train_sft_example.py --max_samples 1000 --num_epochs 1

# 4️⃣ Full training (8-12 hours)
python train_sft_example.py --num_epochs 3

# 5️⃣ Interactive Q&A
python inference_example.py --interactive

# 6️⃣ Evaluate model
python inference_example.py --evaluate --num_samples 50


═══════════════════════════════════════════════════════════════════════════════
KEY FEATURES SUMMARY
═══════════════════════════════════════════════════════════════════════════════

✅ Automatic chat template formatting for DeepSeek-R1
✅ Support for multiple-choice medical questions
✅ Memory-efficient 8-bit quantization
✅ Parameter-efficient LoRA fine-tuning (0.88% params)
✅ Gradient accumulation for large batch sizes
✅ Interactive and batch inference modes
✅ Comprehensive documentation and examples
✅ Production-ready code with error handling
✅ Modular and customizable architecture
✅ Example outputs for validation


═══════════════════════════════════════════════════════════════════════════════
EXPECTED TIMELINE
═══════════════════════════════════════════════════════════════════════════════

Day 1: Setup & Testing
  • Install dependencies               (10 min)
  • Read QUICKSTART_GUIDE.md           (15 min)
  • Run test_preprocessing.py          (30 sec)
  • Inspect examples.json              (10 min)

Day 2: Preprocessing
  • Run full preprocessing             (60 min)
  • Validate processed dataset         (15 min)
  • Quick training test                (10 min)

Day 3-4: Training
  • Start full training                (8-12 hrs)
  • Monitor progress                   (periodic)
  • Evaluate checkpoints               (30 min)

Day 5: Evaluation & Use
  • Test fine-tuned model              (30 min)
  • Run evaluation suite               (1 hr)
  • Interactive demo                   (ongoing)


═══════════════════════════════════════════════════════════════════════════════
SYSTEM REQUIREMENTS
═══════════════════════════════════════════════════════════════════════════════

Minimum (Testing):
  • GPU: 16 GB VRAM (V100)
  • RAM: 32 GB
  • Storage: 20 GB

Recommended (Full Training):
  • GPU: 40 GB VRAM (A100)
  • RAM: 64 GB
  • Storage: 50 GB


═══════════════════════════════════════════════════════════════════════════════
SUPPORT & TROUBLESHOOTING
═══════════════════════════════════════════════════════════════════════════════

Issue                          Solution
────────────────────────────   ───────────────────────────────────────────
Out of Memory                  Use --batch_size 1, reduce --max_length
Training too slow              Increase batch size, reduce max_length
Model not learning             Increase learning rate, more epochs
Import errors                  pip install -r requirements (see docs)
Dataset not found              Check paths in scripts
Poor performance               Add --add_reasoning, increase epochs


═══════════════════════════════════════════════════════════════════════════════
NEXT STEPS
═══════════════════════════════════════════════════════════════════════════════

1. Read README_PMC_VQA_SFT.md
2. Read QUICKSTART_GUIDE.md
3. Run: python test_preprocessing.py
4. Run: python preprocess_pmc_vqa_for_sft.py
5. Run: python train_sft_example.py
6. Run: python inference_example.py --interactive

═══════════════════════════════════════════════════════════════════════════════
Happy Fine-Tuning! 🚀 🏥 🤖
═══════════════════════════════════════════════════════════════════════════════

